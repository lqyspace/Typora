### 第10章 索引优化与查询优化

#### 0. 概述

都有哪些维度可进行数据库调优？简言之：

- 索引失效，没有充分利用到索引——索引建立
- 关联查询太多join（设计缺陷或不得已的需求）——SQL优化（`一般最好不要超过三张表`）
- 服务器调优或各个参数设置（缓冲，线程池等）——调整my.cnf
- 数据过多——分库分表

虽然SQL查询优化的技术很多，但是大方向上完全可以分为`物理查询优化`和`逻辑查询优化`两大块。

- 物理查询优化是通过`索引`和`表连接方式`等技术来进行优化，这里重点需要掌握`索引的使用`。
- 逻辑查询优化是通过`SQL等价交换`提升查询效率，直白一点就是，换一种查询写法执行效率可能更高。

**数据准备**

> 步骤1：建表

```MySQL
CREATE TABLE `class` (
`id` INT(11) NOT NULL AUTO_INCREMENT,
`className` VARCHAR(30) DEFAULT NULL,
`address` VARCHAR(40) DEFAULT NULL,
`monitor` INT NULL,
PRIMARY KEY (`id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

CREATE TABLE `student` (
`id` INT(11) NOT NULL AUTO_INCREMENT,
`stuno` INT NOT NULL ,
`name` VARCHAR(20) DEFAULT NULL,
`age` INT(3) DEFAULT NULL,
`classId` INT(11) DEFAULT NULL,
PRIMARY KEY (`id`)
#CONSTRAINT `fk_class_id` FOREIGN KEY (`classId`) REFERENCES `t_class` (`id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

> 步骤2：设置参数

命令开启：允许创建函数设置

```MySQL
set global log_bin_trust_function_creators=1;  # 不加global只是当前窗口有效
```

> 步骤3：创建函数

保证每跳数据都不同。

```MySQL
# 随机产生字符串
delimiter //
create function rand_string(n Int) returns varchar(255)
begin
declare chars_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
declare return_str varchar(255) default '';
declare i int default 0;
while i<n do
	set return_str = concat(return_str, substring(chars_str, floor(1+rand()*52), 1));
	set i = i+1;
end while;
return return_str;
end //
delimiter ;

# 随机产生班级编号
delimiter //
create function rand_num(from_num int, to_num int) returns int(11)
begin
declare i int default 0;
set i = floor(from_num + rand() * (to_num - from_num + 1));
return i;
end //
delimiter ;


# 创建存储过程
delimiter //
create procedure insert_stu(start int, max_num int)
begin
declare i int default 0;
set autocommit = 0;

repeat
set i = i+1;
insert into student(stuno, name, age, classId) values ((start+i), rand_string(6), rand_num(1, 50), rand_num(1,1000));
until i = max_num
end repeat;

commit;

end //
delimiter ;


# 创建存储过程
delimiter //
create procedure insert_class(max_num int)
begin
declare i int default 0;
set autocommit = 0;
repeat
set i = i+1;
insert into class(classname, address, monitor) values(rand_string(8), rand_string(10), rand_num(1, 100000));
until i = max_num
end repeat;

commit;
end //
delimiter ;

# 调用
call insert_class(100000);
call insert_stu(100000, 500000);

# 删除某表上的索引
DELIMITER //
CREATE PROCEDURE `proc_drop_index`(dbname VARCHAR(200),tablename VARCHAR(200))
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE ct INT DEFAULT 0;
    DECLARE _index VARCHAR(200) DEFAULT '';
    DECLARE _cur CURSOR FOR SELECT index_name FROM
information_schema.STATISTICS WHERE table_schema=dbname AND table_name=tablename AND
seq_in_index=1 AND index_name <>'PRIMARY' ;
#每个游标必须使用不同的declare continue handler for not found set done=1来控制游标的结束
    DECLARE CONTINUE HANDLER FOR NOT FOUND set done=2 ;
    #若没有数据返回,程序继续,并将变量done设为2
    OPEN _cur;
    FETCH _cur INTO _index;
    WHILE _index<>'' DO
        SET @str = CONCAT("drop index " , _index , " on " , tablename );
        PREPARE sql_str FROM @str ;
        EXECUTE sql_str;
        DEALLOCATE PREPARE sql_str;
        SET _index='';
        FETCH _cur INTO _index;
	END WHILE;
CLOSE _cur;
END //
DELIMITER ;
# 调用
call proc_drop_index('dbname', 'tablename');
```



#### **1.** **索引失效案例**

MySQL中`提高性能`的一个最有效的方式是对数据表`设计合理的索引`。索引提供了访问高效数据的方法，并且加快查询的速度，因此索引对查询的速度有着至关重要的影响。

- 使用索引可以`快速地定位`表中的某条记录，从而提高数据库查询的速度，提高数据库的性能。
- 如果查询时没有使用索引，查询语句就会`扫描表中的所有记录`。在数据量大的情况下，这样查询的速度会很慢。

大多数情况下都（默认）采用`B+树`来构建索引。只是空间列类型的索引使用`R-树`，并且MEMORY表还支持`hash索引`。

其实，用不用索引，最终都是优化器说了算。优化器是基于什么的优化器？基于`cost开销(CostBaseOptimizer)`，它不是基于`规则(Rule-BasedOptimizer)`，也不是基于`语义`。怎么样开销小就怎么来。另外，**SQL语句是否使用索引，跟数据库版本、数据量、数据选择度都有关系。**

##### **1.1** **全值匹配我最爱** 

可以根据select语句中的where中的条件创建联合索引，这样查询所用的时间会更低。

##### **1.2** **最佳左前缀法则**

在MySQL建立联合索引时会遵守`最佳左前缀匹配原则`，即最左优先，在检索数据时从`联合索引的最左边开始匹配`。

结论：MySQL可以为多个字段创建索引，一个索引可以包括==16个字段==。对于**多列索引**，**过滤条件要使用索引必须按照索引建立时的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法被使用。**==如果查询条件中没有使用这些字段中第1个字段时，多列（或联合）索引不会被使用==。

```MySQL
create index idx_age_classid_name on student(age, classid, name);
```

比如我们上面创建的索引，我们创建了一个联合索引，当我们进行查询的时候，按照最左前缀原则，当查询（age）、（age，classid）、（age，classid，name）这三种组合的时候可以用到我们定义的联合索引。如果我们查询（age，name），那么我们就只能使用到age的索引了。

我们不用太关心索引的先后顺序，什么意思呢？比如使用（age，classid）和（classid，age）效果是一样的。数据库的查询优化器会自动帮助我们优化我们的SQL，看哪个执行的效率更高，最后才生成最后执行的SQL。

**为什么会有最左前缀原则？**

使用b+树作为索引的存储数据结构时，当我们创建联合索引的时候，比如（age，classis，name），b+树建立索引是从左到右来建立搜索树的，比如当我们来查询where age=30 and classid=4 and name='abcd'，b+树会先通过最左边的（建立索引的字段的左边的字段）字段，也就是age来确定下一步要查询的对象，然后找到classid，再通过classid找到name，所以（classis，name）这样的查询命不中索引。因为最左前缀，一定是从最左边的字段开始一次在B+数的子节点查询，然后确定下一个查询的子节点的数据。所以我们可以使用（age），（age，classid），（age，classid，name）这三种查询条件是可以使用到索引的。

![image-20231012200044445](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122000664.png)

![image-20231012200115846](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122001926.png)

![image-20231012200151199](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122001288.png)

从上面的三张截图可以看出，虽然这三种情况都用到了 `idx_age_classid_name` 索引，但是真正使用的 `key_len`  的长度是不一样的。

**联合索引字段先后顺序的影响？**

联合索引中字段的先后顺序，在SQL层面的执行效率，差别不大，是可以忽略的。无非就是当建立联合索引时，更换索引字段的先后顺序，匹配每个字段锁定的数据条数不一样，但是对最终的查询效率没有太大的影响。但是这个字段的顺序真的就不用考虑了吗？`不是的`，我们知道有最左匹配原则，所以我们要考虑我们的业务，比如说我们的业务场景中有一个字段enterprised，这个字段在80%的查询场景中都会遇到，那么我们肯定首选将这个字段放在联合索引字段的第一个位置，这样就能保证查询的高效，能够命中我们建立的索引。



##### **1.3** **主键插入顺序**

![image-20231012200520046](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122005112.png)

可这个数据页已经满了，再插进来怎么办呢？我们需要把当前`页面分裂`成两个页面，把本页面中的一些记录移动到新创建的这个页面中。页面分裂和记录移动意味着什么？==性能消耗==，所以我们如果想尽量避免这种性能消耗，最好让插入的记录的`主键值依次递增`，这样就不会发生性能消耗了。在插入记录式存储引擎会自动为我们填入自增的主键值。这样的主键占用空间小，顺序写入，减少页面分裂。

**结论：**

对于一个使用`InnoDB`存储引擎的表来说，在我们没有显示的创建索引时，表中的数据实际上都是存储在`聚簇索引`的叶子节点的。而记录又存储在数据页中的，数据页和记录又是按照记录`主键值从小到大`的顺序进行排序，所以如果我们`插入`的记录的`主键值是依次增大`的话，那我们每插满一个数据页就换到下一个数据页继续插，而如果我们插入的`主键值忽小忽大`的话，则可能会造成`页面分裂`和`记录移位`。

##### **1.4** **计算、函数、类型转换(自动或手动)导致索引失效**

##### **1.5** **类型转换导致索引失效**

##### **1.6** **范围条件右边的列索引失效**

> 应用开发中范围查询，例如：金额查询，日期查询往往都是范围查询。**==应将查询条件放置where语句最后==**。（创建的联合索引中，务必把范围涉及到的字段写在最后）

```MySQL
explain select sql_no_cache * from student where age=30 and classid>20 and name='abcd';
```

![image-20231012201853536](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122018645.png)

![image-20231012201954127](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122019211.png)

通过上图我们可以发现：

```MySQL
# 将范围查询的条件放置在语句最后
explain select sql_no_cache * from student where age=30 and name='abc' and classid>20;
# 如果是指单单的改变where子句中索引的顺序是没有意义的，因为查询优化器会自动根据联合索引（age，classid，name）进行排序，所以最后还是把name这个索引省略掉了。
```

![image-20231012202349883](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122023973.png)

==一定要新创建一个联合索引，把范围查询的classid放在最后==。

```MySQL
create index idx_age_name_classid on student(age, name, classid);

explain select sql_no_cache * from student where age=30 and name='abc' and classid>20;
```

![image-20231012210020689](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122100768.png)

![image-20231012210049106](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122100211.png)

由上图可以看出，**成功使用上了所有联合索引的字段**。



##### **1.7** **不等于(!= 或者<>)索引失效** 

```mysql
create index idx_name on student(name);

explain select sql_no_cache * from student where name='abcd';
```

![image-20231012210725228](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122107301.png)

```mysql
explain select sql_no_cache * from student where name<>'abcd';
```

![image-20231012210816861](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122108948.png)



##### **1.8 is null可以使用索引，is not null无法使用索引**

> 结论：最好在设计数据表的时候就将`字段设置为 NOT NULL 约束`，比如你可以将INT类型的字段，默认值设置为0。将字符类型的默认值设置为空字符串('')
>
> 拓展：同理，在查询中使用`not like`也无法使用索引，导致全表扫描

```mysql
explain select sql_no_cache * from student where age is null;
```

![image-20231012211011379](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122110502.png)

```mysql
explain select sql_no_cache * from student where age is not null;
```

![image-20231012212903304](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122129393.png)

```mysql
explain select sql_no_cache * from student where name like 'abc%';
```

![image-20231012213307892](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122133001.png)

```mysql
explain select sql_no_cache * from student where name not like 'abc%';
```

![image-20231012213343265](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122133357.png)

##### **1.9 like以通配符%开头索引失效**

> 拓展：Alibaba《Java开发手册》
>
> 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。

```mysql
explain select sql_no_cache * from student where name like '%abc%';
```

![image-20231012213433355](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122134437.png)

##### **1.10 OR** **前后存在非索引的列，索引失效**

**在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效**。也就是说，**OR前后的两个条件中的列都是索引时，查询中才使用索引。**

##### **1.11** **数据库和表的字符集统一使用utf8mb4**

统一使用utf8mb4( 5.5.3版本以上支持)兼容性更好，统一字符集可以避免由于字符集转换产生的乱码。不同的`字符集`进行比较前需要进行`转换`会造成**索引失效**。

**一般性建议：**

- 对于单列索引，尽量选择针对当前query过滤性更好的索引
- 在选择组合索引的时候，当前query中过滤性最好的字段在索引字段顺序中，位置越靠前越好
- 在选择组合索引的时候，尽量选择能够当前包含query中的where子句中更多字段的索引
- 在选择组合索引的时候，如果某个字段可能出现范围查询时，尽量把这个字段放在索引次序的最后面。

#### **2.** **关联查询优化**

![image-20231012214542110](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122145162.png)

此时给book添加索引。book是被驱动表。

```MySQL
create index Y on book(card);

EXPLAIN SELECT SQL_NO_CACHE * FROM `type` LEFT JOIN book ON type.card = book.card;
```

![image-20231012214801768](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122148925.png)

可以看到第二行的`type`变为`ref`，`rows`也被优化的比较明显。这是由左连接特性决定的。left join 条件用于确定如何从右表搜索行，左边一定都有，所以`右边是我们的关键点`，一定需要建立索引。

如果只能给两个表中的一个表添加索引，那么一定只需要给被驱动表添加索引。

```MySQL
create index X on `type`(card);
explain select sql_no_cache * from `type` left join book on `type`.card = book.card;
```

![image-20231012215352779](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122153834.png)

接着

![image-20231012215424532](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122154581.png)

![image-20231012221005749](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122210810.png)

![image-20231012221145851](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122211935.png)

![image-20231012221205971](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122212044.png)

> 结论1：对于内连接来说，查询优化器可以决定谁来作为驱动表，谁作为被驱动表出现（**被驱动表的成本较低**）
>
> 结论2：对于内连接来讲，如果表的连接条件中只能有一个字段有索引，则有索引的字段所在的表会被作为**被驱动表**
>
> 结论3：对于内连接来说，在两个表的连接条件都存在索引的情况下，会选择**小表作为驱动表**。`小表驱动大表`

##### 

**驱动表和被驱动表：**

join方式连接多个表，本质就是各个表之间数据的循环匹配。MySQL5.5版本之前，MySQL只支持一种表间关联方式，就是嵌套循环（Nested Loop Join）。如果关联表的数据量很大，则join关联的执行时间会非常长。在MySQL5.5以后的版本中，MySQL通过引入BNLJ算法来优化嵌套执行。

==驱动表就是主表，被驱动表就是从表、非驱动表。==

- **对于内连接来说**

  ```MySQL
  select * from A join B on ...
  ```

  A一定是驱动表吗，不一定，优化器会根据你查询语句做优化，决定先用哪张表。**先查询的那张表就是驱动表**，反之就是被驱动表，通过`explain`关键字可以查看。

- **对于外连接来说**

  ```MySQL
  select * from A left join B on ...
  # 或
  select * from B right join A on ...
  ```

  ![image-20231012231802114](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122318294.png)

  ![image-20231012232028813](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122320931.png)

  每从A中取出一条记录，都会把B表中的全部数据加载到内存中，经过了B表中所有的数据的匹配以后，就会把内存中B表的数据删除。然后再从A中取出一条记录，再把B中的所有数据加载到内存中，不断重复以上操作，所以非驱动表的IO次数很多。如果想减少非驱动表的IO次数，可以减少A表中的条目数。

  ![image-20231012232337256](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122323328.png)

##### 2.1 Index Nested-Loop Join（索引嵌套循环连接）

Index Nested-Loop Join其优化的思路主要是为了`减少内层表数据的匹配次数`，所以要求**被驱动表**上必须`有索引`才行。

![image-20231012233249857](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122332955.png)

![image-20231012233358772](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122333872.png)

##### 2.2 Block Nested-Loop Join（块嵌套循环连接）

如果存在索引，那么会使用index的方式进行join，如果join的列没有索引，被驱动表要扫描的次数太多了。每次访问被驱动表，其表中的记录都会被加载到内存中，然后再从驱动表中取一条与其匹配，匹配结束后清除内存，然后再从驱动表中加载一条记录，然后把被驱动表的记录再加载到内存匹配，这样周而复始，大大增加了IO的次数。为了减少被驱动表的IO次数，就需要让A中的条目数少一点，但是A中的条目数是不可控的，因此就想着从A一块一块的加载记录到内存中，比如从A中一次性加载100条记录到内存中，这样就大大减少了IO次数，于是就出现了`Block Nested-Loop Join`的方式。

不再是逐条获取驱动表的数据，而是一块一块的获取，引入了`join buffer缓冲区`，**将驱动表join相关的部分数据列（大小受join buffer的限制）缓存到join buffer中**，然后全表扫描**被驱动表**，**被驱动表的每一条记录一次性和join buffer中的所有驱动表记录进行匹配（内存中操作）**，将简单嵌套循环中的多次比较合并成一次，**降低了被驱动表的访问频率**。

> 注意：
>
> 这里缓存的不只是关联表的列，select后面的列也会被缓存起来。
>
> 在一个有N个join关联的SQL中会分配N-1个join buffer。所以查询的时候尽量减少不必要的字段，可以让join buffer中可以存放更多的列。

![image-20231012234903764](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310122349859.png)

![image-20231017212226659](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310172122833.png)

参数设置：

- block_nested_loop

  通过 `show variables like '%optimizer_switch%'` 查看 `block_nested_loop`状态，默认是开启的。

- join_buffer_size

  驱动表能不能一次加载完，要看join buffer能不能存储所有的数据，默认情况下`join_buffer_size=256k`。

![image-20231017212912894](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310172129972.png)

`join_buffer_size`的最大值在32位系统中可以申请`4G`，而在64位操作系统中可以申请大于`4G`的Join Buffer空间（64位Windows除外，其大值会被截断为`4GB`并发出警告）



**小结：**

- 整体效率比较：`INLJ>BNLJ>SNLJ`

- 永远使用**小结果集**驱动**大结果集**（其本质是为了**减少外层循环的数据量**）（小的度量单位指的是 表行数 * 每行大小）（straight_join的作用是不让查询优化器破坏结构，就让t1当驱动表，t2当被驱动表）

  ```mysql
  select t1.b, t2.* from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=100; # 推荐
  select t1.b, t2.* from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=100; # 不推荐
  ```

- 为**被驱动表匹配的条件增加索引**（减少内层表的循环匹配次数）

- 增大join buffer size的大小（一次缓存的数据越多，那么内层包的扫描次数就越少）

- 减少驱动表不必要的字段查询（字段越少，join buffer所缓存的数据就越多）

  

##### 2.3 Hash Join

**从MySQL的8.0.20版本开始将废弃BNLJ，因为从MySQL8.0.18版本开始就加入了hash join，默认都会使用hash join**

- Nested Loop：对于被连接的数据子集较小的情况下，Nested Loop是个较好的选择。
- Hash Join是做`大数据集连接`时的常用方式，优化器使用两个表中较小（相对较小）的表利用Join Key在内存中建立`散列值`，然后扫描较大的表并探测散列值，找出与Hash表匹配的行。
  - 这种方式适用于较小的表完全可以放入内存中的情况，这样总成本就是访问两个表的成本之和。
  - 在表很大的情况下并不能完全放入内存，这时优化器会将它分割成`若干不同的分区`，不能放入内存的部分就把该分区写入磁盘的临时段，此时要求有较大的临时段从而尽量提高I/O的性能。
  - 它能够很好的工作于没有索引的大表和并行查询的环境中，并提供最好的性能。**Hash Join只能应用于等值连接，这是由Hash的特点决定的**。



**小结：**

- 保证被驱动表的join字段已经创建了索引
- 需要join的字段，数据类型保持绝对一致
- left join时，选择小表作为驱动表，大表作为被驱动表。减少外层循环的次数。
- inner join时，MySQL会自动将`小结果集的表作为驱动表`。选择相信MySQL的优化策略。
- 能够直接多表关联的尽量直接关联，不用子查询（减少子查询的趟数）
- 不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或**使用join来代替子查询**
- 衍生表建不了索引



#### **3.** **子查询优化**

**子查询是** **MySQL** **的一项重要的功能，可以帮助我们通过一个** **SQL** **语句实现比较复杂的查询。但是，子查询的执行效率不高。**原因：

① 执行子查询时，MySQL需要为内层查询语句的查询结果`建立一个临时表`，然后外层查询语句从临时表中查询记录。查询完毕后，再`撤销这些临时表`。这样会消耗过多的CPU和IO资源，产生大量的慢查询。

② **子查询的结果集存储的临时表**，不论是内存临时表还是磁盘临时表都`不会存在索引`，所以查询性能会受到一定的影响。

③ 对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

==**在MySQL中，可以使用连接（JOIN）查询来替代子查询。**连接查询`不需要建立临时表`，其`速度比子查询要快`，如果查询中使用索引的话，性能就会更好。==

> **结论：尽量不要使用NOT IN 或者 NOT EXISTS，用LEFT JOIN xxx ON xx WHERE xx IS NULL替代**

#### **4.** **排序优化**

**问题：**在where条件字段商家索引，但是为什么在order by 字段上还要加索引呢？

**回答：**在MySQL中，支持两种排序规则，分别是`FileSort`和`Index`排序

- `index`排序中，索引可以保证数据的有序性，不需要再进行排序，效率更高。
- `FileSort`排序则一般在`内存中`进行排序，占用`CPU`较多。如果排序结果较大，会产生临时文件IO到磁盘进行排序的情况，效率较低。

**优化建议：**

1. SQL 中，可以在 **WHERE 子句**和 **ORDER BY** 子句中使用索引，目的是在 WHERE 子句中 `避免全表扫描`，在 ORDER BY 子句`避免使用 FileSort 排序`。当然，某些情况下全表扫描，或者 `FileSort` 排序不一定比索引慢。但总的来说，我们还是要避免，以提高查询效率。

2. 尽量使用 `Index` 完成 ORDER BY 排序。如果 WHERE 和 ORDER BY 后面是相同的列就使用单索引列；如果不同就使用联合索引。

3. 无法使用 `Index` 时，需要对 `FileSort` 方式进行调优。

**过程1：无索引**

![image-20231018181028264](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310181810423.png)

**过程2：order by时不limit，它的索引是失效的**

```MySQL
# 创建索引
create index idx_age_classid_name on student(age, classid, name);

# 不限制，索引失效
explain select sql_no_cache * from student order by age, classid;
# 这条语句有可能会造成索引失效，为什么是有可能呢，这是因为用不用联合索引与数据量和select的字段有关系的。从结果上来看，我们发现他并没有使用联合索引，这是根据查询优化器的查询策略选择的，假如是根据联合索引进行查询，由于是二级索引，且查询的是所有的字段，所以查询语句会进行回表操作，如果数据量很大的话，那么耗时也是很大的。然后查询优化器进过比较发现，将所有的数据加载到内存然后进行排序所花费的时间比用索引所花费的时间还少，因此就索性不使用联合索引了。

# 使用上了联合索引
explain select sql_no_cache age, classid from student order by age, classid;
# 使用上了联合索引，这是因为根据联合索引排序后，select所查询的字段也是联合索引字段，根本就不用进行回表操作，可以直接返回结果。这就是覆盖索引。
```

![image-20231018183305942](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310181833116.png)

```MySQL
# 增加limit过滤条件，使用联合索引
explain select sql_no_cache * from student order by age, classid limit 10;
# 这个会使用上联合索引，是因为只需要取前10条数据，所以索性直接使用联合索引进行排序然后去前10条进行回表，这种方式总比把所有的数据加载到内存然后把所有的数据进行排序所花费损耗小，因此查询优化器会选择第一种方式。
```

![image-20231018183709875](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310181837020.png)

**过程3：order by时顺序错误，索引失效**

```MySQL
# 创建索引
create index idx_age_classid_stuno on student(age, classid, stuno);
# 以下哪些索引失效
explain select * from student order by classid limit 10; # 失效
explain select * from student order by classid,name limit 10; # 失效
explain select * from student order by age, classid, stuno limit 10; # 有效
explain select * from student order by age, classid limit 10; # 有效
explain select * from student order by age limit 10; # 有效
```

![image-20231018193217001](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310181932403.png)

**有一点区别**：在where语句里，如果使用联合索引中的字段进行过滤，那么使用到的字段就是实际使用到的字段，所以key_len的长度就是使用到的实际字段的长度。但是在order by用到的联合索引的某个索引时，实际的key_len的长度就是所有联合索引的字段的长度。

![image-20231018193741475](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310181937600.png)

**过程4：order by时规则不一致，索引失效（顺序错，不索引；方向反，不索引）**

```MySQL
explain select * from student order by age desc, classid asc limit 10;# 失效，因为age降序
explain select * from student order by classid desc, name desc limit 10; # 失效，第一不符合最左匹配原则，第二classid降序
explain select * from student order by age asc, classid desc limit 10; # 失效，假设用了联合索引，先按照age查找，然后又classid降序，发现还不如不用联合索引，直接按照age升序，classid降序然后取前10条数据更快。
explain select * from student order by age desc, classid desc limit 10;# 有效，倒着遍历
```

![image-20231018204614772](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182046568.png)

**过程5：无过滤，不索引**

```MySQL
explain select * from student where age=45 order by classid;
```

![image-20231018204820988](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182048028.png)

我们发现：classid这个索引并没有用上，因为key_len的值为5，很明显只用了一个索引字段，这是因为经过where的过滤条件以后，数据量就很少了，所以就没有必要继续使用classid索引了，所以就没有用

```MySQL
explain select * from student where age=45 order by classid, name;
```

![image-20231018205139669](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182051946.png)

效果和上面的一样。

```MySQL
explain select * from student where classid=45 order by age;

explain select * from student where classid=45 order by age limit 10;
```

![image-20231018205446430](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182054663.png)

第一条语句没有使用上索引，第二条语句使用到了索引。

第二条语句是先进行order排序，排完序以后再进行过滤最后取前10个。这个效率要比第一条语句高，第一条语句相当于在内存加载了所有的数据，也就是全表的`FileSort`，用age进行排序，然后再进行过滤，而且也没有limit限制，消耗的性能可能更高，因此第一条语句没有使用到索引，而第二条语句使用到了索引。

如果给`classid`单独建一个索引，那么classid就一定可以被用上。

所以最终的执行路径是要看`查询优化器的选择`。

**小结：**

![image-20231018210207769](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182102927.png)

**实战：测试FileSort和Index排序**

![image-20231018212323527](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182123784.png)

> 结论：在没有索引的情况下，type是ALL类型，即最坏的情况。Extra里还出现了Using fileSort，也是最坏的情况。必须优化。

优化思路：

方案一：为了去掉fileSort我们可以把索引建成

```MySQL
create index idx_age_name on student(age, name);
```

方案二：尽量让where的过滤条件和排序使用上索引

```MySQL
CREATE INDEX idx_age_stuno_name ON student (age,stuno,NAME);
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno <101000 ORDER BY
NAME ;
```

![image-20231018213141240](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182131355.png)

查询优化器认为经过age和stuno过滤，查询效率已经很高了，所以根本就没有使用上name。

这个语句相对上面一个查询语句来说，效率更高，因为上面的语句只使用到了age这一个索引，而这个语句使用到了两个索引。

也就是说，并不是Extra里面出现了fileSort我们一定要把fileSort出掉。

原因：

所有的排序都是在条件过滤之后才执行的。所以，如果条件过滤掉大量的数据，剩下几百几千条数据进行排序其实并不是很消耗性能，即使索引优化了排序，但实际提升性能有限。相对的stuno<101000这个条件，如果没有用到索引的话，要对几万条的数据进行扫描，这是非常消耗性能的，所以索引放到这个字段上性价比是最高的，是最优的选择。

> 结论：
>
> 1. 两个索引同时存在时，查询优化器自动选择最优的方案。（对于这个例子，MySQL选择了idx_age_stuno_name）。但是，`随着数据量的变化，选择的索引也会随之变化`。
> 2. 当【范围条件】和【group by或者order by】的字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数量足够多，而需要排序的数量并不多时，优先把索引放在过滤字段上。反之，如果过滤的数量并不是很多，那么就有可能需要在排序的字段上添加索引。

![image-20231018214456157](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182144243.png)

答案是可行的，因为查询优化器根本就没有用上name这个字段的索引。只用上了前两个字段的索引。

##### 4.1 fileSort算法：双路排序和单路排序

排序的字段如果不在索引列上，则`fileSort`会有两种算法：`双路排序`和`单路排序`

`双路排序（慢）`

- MySQL 4.1之前使用双路排序，字面意思就是扫描两次磁盘，最终得到数据，读取主键id和Order by列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。

  - ```MySQL
    select * from user where name='李白' order by age;
    ```

  - 从索引`name`找到第一个满足`name=’李白‘`的主键id

  - 根据主键id取出整行，把`排序字段age`和`主键id`这两个字段放到sort buffer（排序缓存）中

  - 从索引`name`取下一个满足条件记录的`主键id`和`age`

  - 重复上面的过程

  - ==对sort buffer中的字段age和主键id按照字段age进行排序==

  - 遍历排好序的id和字段age，按照id的值回到原来的表中取出所有的字段的值返回给客户端

取一批数据，要对磁盘进行两次扫描，从所周知，IO是很耗时的，所以MySQL4.1之后，出现了第二种改进的算法，就是单路排序。

`单路排序（快）`

从磁盘读取查询需要的所有列，按照order by列在buffer对他们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成顺序IO，但是它会使用更多的空间，因为他把每一行都保存在了内存中。

- 从索引name找到第一个满足name='李白'条件的主键id
- 根据主键id取出整行，取出所有字段的值，存入sort buffer（排序缓存）中
- 从索引name找到下一个满足name='李白'条件的主键id
- 重复上述过程
- 对sort buffer中的数据按照字段age进行排序
- 返回结果给客户端

**对比：**

其实对比两个排序模式，单路排序会把所有需要查询的字段都放到sort buffer中，而双路排序只会把`主键`和需要排序的字段放到sort buffer中进行排序，然后再通过主键回到原表查询需要的字段。

**选型：**

至于MySQL优化器使用双路排序还是单路排序是有自己的算法的，如果查询的列字段大于`max_length_for_sort_data`变量，则会使用双路排序，反之则会使用单路排序。单路排序的速度是更快的，不过比较占内存，如果在内存空间允许的情况想要使用单路排序的话，可以增加`max_length_for_sort_data`变量的大小，`max_length_for_sort_data`变量默认为1024字节。

**注意：**

如果全部使用sort buffer内存排序，一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大sort buffer（默认1M），MySQL很多参数设置都是经过优化的，不要轻易调整。

**order by关键字优化：**

- order by子句，尽量使用Index方式排序，避免使用FileSort方式排序
- MySQL支持两种排序方式，`FIleSort`和`Index`，`Index`效率较高，`FileSort`方式效率较低
- 尽可能在索引列上完成排序操作，遵循索引建的最左匹配原则

![image-20231018233115466](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182331591.png)

**优化策略：**

1. 尝试提高sort_buffer_size

   不管用哪种算法，提高这个参数都会提高效率，要根据系统的能力去提高，因为这个参数是针对每个进程（connection）的1M-8M之间调整的。MySQL5.7中Innodb存储引擎的默认值是1048576字节，1MB。

   ![image-20231018233459850](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182334936.png)

2. 尝试提高`max_length_for_sort_data`

   提高这个参数，会增加用改进算法的概率。

   ![image-20231018233725904](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310182337988.png)

   如果设得太高，数据总容量超出`sort_buffer_size`的概率就增大，明显症状是高的磁盘IO和低的处理器使用率。如果需要返回的列的总长度大于`max_length_for_sort_data`，使用双路算法，否则使用单路算法。1024-8192字节之间调整。

3. order by时select * 是一个大忌。最好只用Query需要的字段。原因：

   - 当query字段的大小小于`max_length_for_sort_data`，而且排序字段不是TEXT|BLOB类型时，会用改进后的算法——单路排序，否则用老算法——多路排序。
   - 两种算法的数据都有可能超出`sort_buffer_size`的容量，超出之后，会创建tmp文件进行合并排序，导致多次IO，但是用单路排序算法的风险更大一些，所以要提高`sort_buffer_size`

#### **5. GROUP BY优化**

- group by 使用索引的原则几乎跟order by一致 ，group by 即使没有过滤条件用到索引，也可以直接使用索引。
- group by 先排序再分组，遵照索引建的最佳左前缀法则
- 当无法使用索引列，可以增大`max_length_for_sort_data`和`sort_buffer_size`参数的设置
- where效率高于having，能写在where限定的条件就不要写在having中了
- 减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。Order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。
- **包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。**

#### **6.** **优化分页查询**

一般分页查询时，通过创建覆盖索引能够比较好地提高性能。一个常见又非常头疼的问题就是limit 2000000, 10，此时需要通过MySQL排序前2000010条记录，仅仅返回2000000-2000010的记录，其他的纪录丢弃，查询排序的代价非常大。

```MySQL
explain select * from student limit 2000000,10;
```

![image-20231019124921962](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191249068.png)

**优化思路一**

在==索引上完成排序分页操作==，最后根据主键关联回原表查询所需要的其他列内容。

```mysql
EXPLAIN SELECT * FROM student t,(SELECT id FROM student ORDER BY id LIMIT 2000000,10) a
WHERE t.id = a.id;
```

**优化思路二**

该方案适用于主键自增的表，可以把Limit 查询转换成某个位置的查询。

```mysql
EXPLAIN SELECT * FROM student WHERE id > 2000000 LIMIT 10;
```

#### **7.** **优先考虑覆盖索引**

##### **7.1** **什么是覆盖索引？**

**理解方式一**：索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据；**当能通过读取索引就可以得到想要的数据，那就不需要读取行了**。**一个索引包含了满足查询结果的数据就叫做覆盖索引。**

**理解方式二**：非聚簇复合索引的一种形式，它包括在查询里的SELECT、JOIN和WHERE子句用到的所有列（**即建索引的字段正好是覆盖查询条件中所涉及的字段**）。

简单说就是，`索引列+主键`包含`SELECT 到 FROM之间查询的列`。

**举例1：**

```mysql
drop index idx_age_stuno on student;
create index idx_age_name on student (age, name);
explain select * from student where age<>20;
```

![image-20231019134613838](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191346999.png)

```mysql
explain select age, name, id from student where age<>20;# 不用回表
```

![image-20231019134723463](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191347593.png)

不要理解成如果出现 `!=` 或 `<>` 就一定不适用索引，主要还是基于成本的考虑。

所以这个例子使用上了**索引**。

```mysql
explain select * from student where name like '%abc';
explain select age, name, id from student where name like '%abc';
```

![image-20231019161913374](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191619590.png)

所以基于**成本**。

##### **7.2** **覆盖索引的利弊**

**好处：**

**1.** **避免Innodb表进行索引的二次查询（回表）**

Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据，在查找到相应的键值后，还需通过主键进行二次查询才能获取我们真是需要的数据。

在覆盖索引中，二级索引的键值可以直接获取所要的数据，避免了对主键的二次查询，减少了IO操作，提升了查询效率。

**2.** **可以把随机IO变成顺序IO加快查询效率**

由于覆盖索引是按照键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的IO转换成索引查找的顺序IO。

由于索引是顺序存储的，所以对于二级索引来说，如果需要回表的话，那么到主表查询时位置就不一定是连续的。但是如果是覆盖索引的话，那么就不会涉及到回表的问题，所以就没有了随机IO，也就是在范围查找时变成了顺序IO。

==由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。==

**弊端：**

`索引字段的维护`总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这是业务DBA，或者称为业务数据架构师的工作。

> **前缀索引的影响：对于字符串，可以创建前缀索引，如果不创建前缀索引，那么索引就会包含整个字符串。使用前缀索引，定义好长度，就可以既做到节省空间，也可以做到不用增加额外的查询成本。**
>
> 前面已经讲过区分度的问题，区分度越高越好，因为区分度越高，意味着重复的键值就越少。
>
> 结论：
>
> 使用前缀索引就不用了覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

#### **8.** **索引条件下推**

Index Condition Pushdown（ICP）是MySQL5.6中的新特性，是一种在存储引擎层使用索引过滤数据的优化方式。

- 如果没有ICP，存储引擎会遍历索引以定位基表中的行，并将它们返回给MySQL服务器，MySQL服务器评估where后面的条件是否保留行。
- 启用ICP后，如果部分where条件可以仅使用索引中的列进行筛选，则MySQL服务器会把这部分where条件放到存储引擎筛选。然后，存储引擎通过使用索引条目来筛选数据，并且只有在满足这一条目时才从表中读取行。
  - 好处：ICP可以减少存储引擎必须访问基表的次数和MySQL服务器必须访问存储引擎的次数。
  - 但是：ICP的加速效果取决于在存储引擎内通过ICP筛选掉的数据的比例。

**举例：**

```MySQL
create table people (
    -> id int not null auto_increment,
    -> zipcode varchar(20) collate utf8_bin default null,
    -> firstname varchar(20) collate utf8_bin default null,
    -> lastname varchar(20) collate utf8_bin default null,
    -> address varchar(20) collate utf8_bin default null,
    -> primary key(id),
    -> key zip_last_first(zipcode, lastname, firstname)
    -> )
    -> engine=innodb auto_increment=5 default charset=utf8mb3 collate=utf8_bin;
    
    
insert into people values
    -> (1, '000001', '三', '张', '北京市'),
    -> (2, '000002', '四', '李', '南京市'),
    -> (3, '000003', '五', '王', '上海市'),
    -> (4, '000001', '六', '赵', '天津市');
    
explain select * from people where zipcode='000001' and lastname like '%张%' and address like '%北京市%';
```

![image-20231019181713969](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191817135.png)

如果没有使用索引下推，那么就会根据第一次过滤得到主键回表查询整行数据，如果第一次过滤以后数据量还是很大的话，那么回表的次数就会很多，就特别影响性能。

但是如果使用了索引下推，经过第一次过滤以后不用直接回表，而是根据第二个过滤条件再把数据进行一次过滤，此时得到的主键条数就会减少，由于address不属于索引，所以address并不会使用到索引下推。

```MySQL
# 如果不想使用using where
explain select * from people where zipcode='000001' and lastname like '%张%';
```

**开启和关闭存储引擎：**

```MySQL
set optimizer_switch = 'index_condition_pushdown=off';
set optimizer_switch = 'index_condition_pushdown=on';
```

##### **8.1** **使用前后的扫描过程**

**在不使用ICP索引扫描的过程：**

storage层：只将满足**index key**条件的索引记录对应的整行记录取出，返回给server层 

server 层：对返回的数据，使用后面的where条件过滤，直至返回最后一行。

![image-20231019190528814](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191905102.png)

![image-20231019190710442](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191907692.png)

**使用ICP扫描的过程：**

storage层：首先将index key条件满足的索引记录区间确定，然后在索引上使用index filter进行过滤。将满足的index filter条件的索引记录才去回表取出整行记录返回server层。不满足index filter条件的索引记录丢弃，不回表、也不会返回server层。

server 层：对返回的数据，使用table filter条件做最后的过滤。

![image-20231019190846455](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310191908611.png)

![image-20231019200630660](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192006896.png)

![image-20231019200726498](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192007821.png)

**ICP的使用条件**

1. 如果表访问类型为`range`，`ref`，`eq_ref`和`ref_or_null`可以使用`ICP`
2. ICP可以用于`Innodb`和`MyISAM`表，包括分区表`Innodb`和`MYISAM`表
3. 对于`Innodb`表，ICP仅用于二级索引。ICP的目标是减少全行读取次数，从而减少IO操作。
4. **当SQL使用覆盖索引时，不支持ICP**。因为这种情况下使用ICP不仅减少IO
5. 相关子查询的条件不能使用ICP
6. 由于ICP在使用时不会回表，所以ICP不会和聚集索引，覆盖索引一起用。

![image-20231019202629948](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192026039.png)

![image-20231019202646355](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192026495.png)

#### **9.** **其它查询优化策略**

##### **9.1 EXISTS** **和** **IN** **的区分**

索引是个前提，其实选择与否还会要看表的大小。你可以将选择的标准理解为`小表驱动大表`。

比如下面这样：

```MySQL
select * from A where cc in (select cc from B);

select * from A where exists (select cc from B where B.cc=A.cc);
```

当A表小于B表时，用Exists，因为Exists的实现，相当于外表循环，实现的逻辑类似于：

```java
for i in A
    for j in B
        if j.cc==i.cc then ...
```

当B表小于A表时，使用IN，其实现逻辑

```MySQL
for i in B
	for j in A
		if j.cc==i.cc then ...
```

哪个表小就用哪个表来驱动，A表小就用Exists，B表小就用IN。

##### **9.2 COUNT(\*)与COUNT(具体字段)效率**

**环节1：**`COUNT(*)`和`COUNT(1)`都是对**所有结果**进行`COUNT`，`COUNT(*)`和`COUNT(1)`本质上并没有区别（二者执行时间可能略有差别，不过你还是可以把它俩的执行效率看成是相等的）。如果有WHERE子句，则是对所有符合筛选条件的数据行进行统计；如果没有WHERE子句，则是对数据表的数据行数进行统计。

**环节2：**如果是MyISAM存储引擎，统计数据表的行数只需要`O(1)`的复杂度，这是因为每张MyISAM的数据表都有一个meta信息存储了`row_count`值，而一致性则是由表级锁来保证的。

如果是InnoDB存储引擎，因为InnoDB支持事务，采用行级锁和MVCC机制，所以无法像MyISAM一样，维护一个row_count变量，因此需要采用`扫描全表`，是`O(n)`的复杂度，进行**循环+计数**的方式来完成统计。

**环节3：**在InnoDB引擎中，如果采用`COUNT(具体字段)`来统计数据行数，要尽量采用二级索引。因为主键采用的索引是聚簇索引，聚簇索引包含的信息多，明显会大于二级索引（非聚簇索引）。对于`COUNT(*)`和`COUNT(1)`来说，它们不需要查找具体的行，只是统计行数，系统会`自动`采用占用空间更小的二级索引来进行统计。

如果有多个二级索引，会使用key_len小的二级索引进行扫描。当没有二级索引的时候，才会采用主键索引来进行统计。

##### **9.3** **关于SELECT(\*)**

在表查询中，建议明确字段，**不要使用 * 作为查询的字段列表**，推荐使用SELECT <字段列表> 查询。原因：

① MySQL 在解析的过程中，会通过`查询数据字典`将"*"按序**转换成所有列名**，这会大大的耗费资源和时间。

② 无法使用`覆盖索引`

##### **9.4 LIMIT 1** **对优化的影响**

针对的是会扫描全表的 SQL 语句，如果你可以确定结果集只有一条，那么加上`LIMIT 1`的时候，当找到一条结果的时候就不会继续扫描了，这样会加快查询速度。

如果数据表已经对字段建立了唯一索引，那么可以通过索引进行查询，不会全表扫描的话，就不需要加上`LIMIT 1`了。

##### **9.5** **多使用COMMIT**

只要有可能，在程序中尽量多使用 COMMIT，这样程序的性能得到提高，需求也会因为 COMMIT 所释放的资源而减少。

COMMIT 所释放的资源：

- 回滚段上用于恢复数据的信息

- 被程序语句获得的锁

- redo / undo log buffer 中的空间

- 管理上述 3 种资源中的内部花费



#### 10 淘宝主键是如何设计的

![image-20231019213652208](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192136323.png)

![image-20231019213951055](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192139185.png)

![image-20231019214032350](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192140449.png)

![image-20231019214052267](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192140423.png)

![image-20231019215114372](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192151519.png)

![image-20231019215249085](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192152247.png)

![image-20231019215407453](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192154548.png)

![image-20231019220238434](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192202551.png)

![image-20231019220308225](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192203324.png)

UUID是长度36的字符串，除去中间的“-”，那么就是32个字节，由于每个字节是用16进制的，也就是占4位，因此一共占32*4位，转成二进制进行存储以后，由于一个字节是8位，所以`32 * 4 / 8 = 16`字节。

![image-20231019221659569](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192216710.png)

![image-20231019221822996](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202310192218652.png)