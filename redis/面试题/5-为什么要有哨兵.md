# 为什么要有哨兵

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290020232.png)

## 为什么要有哨兵机制

在Redis的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

![主节点挂了](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290023025.png)

这时如果要恢复服务的话，需要人工介入，选择一个从节点切换为主节点，然后让其他的从节点指向新的主节点，同时还要通知上游那些链接Redis主节点的客户端，将其配置中的主节点的ip改为新主节点的IP地址。

这样也太不智能了，要是有一个节点能监控 **主节点** 的状态，当发现主节点挂了，它自动将一个从节点切换为主节点的话，那么可以节省我们很多事情。

Redis在2.8版本以后提供了==哨兵机制（Sentinel）==，它的作用是实现==主从节点故障转移==，它会检测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。



## 哨兵机制是如何工作的

哨兵其实是一个运行在特殊模式下的Redis进程，所以它也是一个节点。从哨兵这个名字也可以看出，它相当于是观察者节点，观察的对象是主从节点。

当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些动作，来修复异常状态。

哨兵节点主要负责三件事：==监控、选主、通知==

![哨兵的职责](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290035991.png)

所以，我们重点学习这三件事情：

- 哨兵是如何监控节点的？又是如何判断主节点是否真的故障了？
- 根据什么规则选择一个从节点切换为一个主节点？
- 怎么把新主节点的相关信息通知给从节点和客户端呢？



## 如何判断主节点真的故障了？

哨兵会每隔1s给所有的主从节点发送PING命令，当主从节点收到PING命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。

![哨兵监控主从节点](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290042600.png)

**如果主节点或者从节点没有在规定的时间内响应命令，哨兵就会将他们标记为** ==**主观下线**==。这个规定的时间是配置了 down-after-milliseconds 参数设定的，单位是毫秒。

> **主观下线？难道还有客观下线？**

是的，没错，**客观下线只适用于主节点。**

之所以针对 **主节点** 设计 **主观下线**和 **客观下线**两个状态，是因为有可能主节点并没有故障，可能只是因为主节点的系统压力比较大或者网络发生了拥塞，导致主节点没有在规定的时间内响应哨兵的PING命令。

所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。**同时，多个哨兵的网络同时不稳定的概率比较小，由他们一起做决策，误判率会比较低。

具体是怎么判断主节点是客观下线呢？

当一个哨兵判断一个主节点为 ==主观下线== 后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票和拒绝投票的响应。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290053841.png)

==当这个哨兵的赞成票数达到哨兵配置文件中的quorum配置项设定的值后，这时主节点就会被该哨兵标记为 **客观下线**。==

例如，现在有3个哨兵，quorum配置的是2，那么一个哨兵需要2张赞成票，就可以标记主节点为 ==客观下线==，这两张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

**PS：quorum的值一般设置为哨兵的个数的二分之一加一，例如3个哨兵就设置为2。**

哨兵判断完主节点客观下线后，哨兵就要开始在多个从节点中，选举出一个从节点来做新主节点。



## 由哪个哨兵进行主从故障转移？

前面说过，为了更加客观的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样就可以减少误判率，所以 ==哨兵是以哨兵集群的形式存在的。==

问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？

所以这个时候还需要在哨兵集群中选举出一个leader，让leader来执行主从切换。

选举leader的过程其实是一个投票的过程，在投票开始前，肯定得有个候选者。

> **那谁来作为候选者呢？**

哪个哨兵节点判断主节点为客观下线，这个哨兵节点就是候选者，所谓的候选者就是相当leader的哨兵。

举个例子，假如哨兵有三个，当哨兵B先判断主节点为主观下线后，就会给其他实例发送 is-master-down-by-addr命令。接着，其他哨兵会根据自己和主节点的网络情况，做出赞成投票和拒绝投票的响应。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307290108513.png)

当哨兵B收到的赞成票数达到哨兵配置文件中quorum配置项设定的值后，就会将主节点标记为客观下线，此时的哨兵B就是一个Leader候选者。



> **候选者如何选举成为Leader？**

候选者会向其他哨兵发送命令，表明希望成为Leader来执行主从切换，并让所有其他的哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程，任何一个候选者要满足两个条件：

- 第一，拿到半数以上的赞成票
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的quorum值

举个例子，假如哨兵节点有3个，quorum设置为2，那么任何一个想成为Leader的哨兵只要拿到2张赞成票，就可以选举成功。如果没有满足条件，就需要重新进行选举。

这时候有同学就问了，如果某个时间点，刚好有两个哨兵节点判断主节点为客观下线，那这是不就有两个候选者，这时该如何决定谁是Leader呢？

每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到候选者A的投票请求，就会先投给它，如果投票者用完投票机会后，收到候选者B的投票请求，就会拒绝投票。这时，候选者A先满足了上面的那两个条件，所以候选者A成为Leader。



> **为什么哨兵节点至少要有三个？**

如果哨兵集群中只有两个哨兵节点，如果此时一个哨兵节点想要成为Leader，必须获得半数以上的票数，即2票，而不是1票。

所以，如果哨兵集群中有一个哨兵挂掉了，那么就只剩下一个哨兵，如果这个哨兵想要成为Leader，这是票数就没办法达到2票，就无法成为Leader，主从切换就无法进行。

因此，通常我们至少配置3个哨兵节点。这时，如果有一个哨兵挂掉了，那么还剩下两个哨兵，如果这个哨兵想要成为Leader，这时还是有机会达到2票的，所以还是可以选举成功的，不会导致无法进行主从切换。

当然，如果你要问3个哨兵节点挂了2个哨兵节点，怎么办？那就住能人为介入了，或者多增加一些哨兵节点。

再说一个问题，Redis 1主4从，5个哨兵，quorum设置为3，如果2个哨兵故障了，当主节点宕机时，哨兵能否判定主节点“客观下线”，主从能否自动切换。

- ==哨兵集群可以判定主节点客观下线==：哨兵集群还剩3个哨兵节点，当一个哨兵判断主节点“主观下线”后，询问另外2个哨兵的意见，有可能拿到3张同意票，这时就达到了quorum设置的值，因此哨兵集群可以判定主节点是否为“客观下线”
- ==哨兵集群可以完成主从切换==：当有个哨兵标记主节点为 “客观下线”后，就会进行选举Leader的过程，因为此时哨兵集群还剩3个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了quorum值，满足了选举Leader的两个条件，所以就能选举成功，因此哨兵集群可以完成主从切换。

如果quorum设置为2，并且如果有3个哨兵节点出现故障，此时哨兵集群还是可以判定主节点为 **客观下线**，但是哨兵不能完成主从切换，是因为已经有3个哨兵节点出现故障，如果进行Leader选举的话，最多能拿到2张同意票，达不到半数以上的条件，因此不能选举出Leader，所以也就无法进行主从切换。

如果quorum设置为3，并且如果有3个哨兵故障的话，哨兵集群既不能判定主节点为客观下线，也不能进行主从切换。

可以看到，quorum为2的时候，并且有3个节点故障的话，虽然可以判定主节点为客观下线，但是依旧不能进行主从切换，因此感觉 **判定主节点为客观下线**这件事情白做了一样，既然这样，还不如不做。当quorum为3的时候，就可以避免这种无用功。

所以，quorum的值建议设置在哨兵个数的二分之一加一，例如3个哨兵就设置2，5个哨兵就设置3，而且哨兵节点的数量应该是奇数。



## 主从故障转移的过程是怎么样的？

在哨兵集群中通过投票的方式，选举出哨兵leader后，就可以进行主从故障转移的过程了，如下图：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307292246181.png)

主从故障转移包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有从节点里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有从节点修改复制目标，修改为复制新主节点。
- 第三步：将新主节点的ip地址和信息，通过 ==发布者/订阅者机制== 通知给客户端。
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点。



> **步骤一：挑选出新主节点**

故障转移操作的第一步就是在已下线的主节点的从节点中，挑选出一个状态良好，数据完整的从节点，然后想这个从节点发送 `SLAVEOF no one`命令，将这个从节点转换为主节点。

那么从节点到底选择哪个从节点作为主节点呢？

随机的方式好吗？随机的方式实现起来比较简单，但是如果选到一个网络状态不好的从节点作为新主节点，那么可能在不久的将来又要做一次主从故障转移。

所以，我们首先要把网络状态不好的从节点给过滤掉。首先把已经下线的从节点过滤掉，然后把以往网络状态连接不好的从节点过滤掉。

怎么判断从节点之前的网络状态不好呢？

Redis有个叫down-after-milliseconds * 10 配置项，其down-after-milliseconds是主从节点断连的最大连接超时时间。如果在down-after-milliseconds毫秒内，主从节点都没通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过10次，就说明这个从节点的网络状态不好，不适合作为新主节点。

至此我们就把网络状态不好的从节点给过滤掉了，接下来要对所有的从节点进行三轮考察：**优先级、复制进度、ID号**。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其为新主节点。

- 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前
- 第二轮考察：如果优先级相同，则查看复制的进度，哪个从 主节点接受的复制数据多，哪个就考前。
- 第三轮考察：如果优先级和复制进度都相同，就选择从节点ID较小的那个。



**第一轮考察：优先级较高的从节点胜出**

Redis有一个配置项叫 slave-priority，可以给从节点设置优先级。

每一台从节点的服务器配置不一定是相同的，我们可以根据服务器性能配置来设置从节点的优先级。

比如，如果A从节点的物理内存是所有从节点当中最大的，那么我可以把A从节点的优先级设置为最高。这样当哨兵进行第一轮考察的时候，优先级最高的A从节点就会胜出，于是成为新主节点。



**第二轮考察：复制进度最靠前的从节点胜出**

如果第一轮的考察中发现优先级最高的从节点有两个，那么就会进行第二轮考察，比较两个从节点哪个复制进度更多一些。

什么是复制进度？主从架构中，主节点会将写操作同步给从节点。在这个过程中，主节点会用master_repl_offset记录当前的最新写操作在repl_backlog_buffer中的位置（如下图中的 主服务已经写入的数据 的位置），从节点会用slave_repl_offset这个值来记录当前的复制进度（如下图中的 从服务器要读的 位置）。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307300005657.png)

如果某个从节点的slave_repl_offset最接近master_repl_offset，说明它的复制进度是最靠前的，于是就可以将它选为新主节点。



**第三轮查察：ID号小的从节点胜出**

如果在第二轮考察中发现有两个从节点优先级和复制进度都是一样的，那么就会进行第三轮考察，比较两个从节点的ID号，ID号小的从节点胜出。

什么是ID号？每个从节点都有一个编号，这个编号就是ID号，是用来唯一标识从节点的。

到这里选主的事情终于结束了。简单跟大家总结说一下：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302209994.webp)

在选出从节点后，哨兵Leader向被选中的从节点发送 `SLAVEOF no one`命令，让这个从节点解除从节点身份，将其变为新主节点。

如下图所示，哨兵Leader向被选中的从节点slave2发送 `SLAVEOF no one`命令，将该从节点升级为新主节点。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302220563.png)

在发送 `SLAVEOF no one`命令以后，哨兵leader会以每秒一次的频率向**被升级的从节点**发送INFO命令（没进行故障转移之前，INFO命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的slave变为master时，哨兵leader就知道了被选中的从节点已经顺利地升级为主节点。

如下图所示，选中的从节点slave2升级为新主节点：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302224542.png)



**需要注意的是，一旦新的主节点被选举出来，所有哨兵实例都会将新的主节点添加到自己的配置文件中，并停止向故障实例发送PING命令。**



> **步骤二：将从节点指向新主节点**

当新主节点出现之后，哨兵leader下一步要做的就是，让已下线的主节点属下的所有从节点指向新主节点，这一动作可以通过向从节点发送 `SLAVEOF`命令来实现。

如下图，哨兵leader向所有从节点（server3和server4）发送 `SLAVEOF`，让他们成为新主节点的从节点。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302229687.png)

所有从节点指向新主节点后的拓扑图如下：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302230058.png)

> **通知客户端主节点已更换**

通过前面一系列的操作之后，哨兵集群终于完成了主从切换的工作，那么新主节点的信息要如何通知给客户端？

这主要通过Redis的 ==发布者/订阅者== 机制来实现的，每个哨兵节点提供==发布者/订阅者==机制，客户端可以从哨兵订阅信息。

哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件，几个常见的事件如下：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302233046.webp)



客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。==主从切换完成后，哨兵就会向`+switch-master`频道发布新主节点的IP地址和端口信息，这个时候客户端就可以收到这条信息，然后用这里的新主节点的IP地址和端口号进行通信了。==

通过 ==发布者/订阅者== 机制，有了这些事件的通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样客户端就可以知道主从节点进行到哪一步了，有助于了解切换进度。



> **步骤四：将旧主节点变为从节点**

故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 `SLAVEOF`命令，让它成为新主节点的从节点，如下图所示：

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302243052.png)



至此，整个故障转移的工作结束。



## 哨兵集群是如何组成的

前面提到了Redis的发布者/订阅者机制，那就不得不说说哨兵集群的组成方式，因为它也用到了这个技术。

在我第一次搭建哨兵集群的时候，当时觉得很诧异。因为在配置每一个哨兵的信息时，竟然只需要填写下面几个参数即可，设置主节点名字，主节点的IP地址和端口号以及quorum值。

```c
sentinel monitor <master-name> <ip> <redis-port> <quorum>
```

不需要填写其他节点的信息，我就好奇他们是如何感知对方的，有是如何组成哨兵集群的？

后面才了解到，==哨兵节点之间是通过Redis的发布者/订阅者机制来相互发现的。==

在主从集群中，主节点上有一个名为 `__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

在下图中，哨兵A把自己的IP地址和端口的信息发布到 `__sentinel__:hello`频道上，哨兵B和哨兵C订阅了该频道。那么此时，哨兵B和哨兵C就可以从这个频道直接获取哨兵A的ip地址和端口号。然后，哨兵B，C可以和哨兵A建立网络连接。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307302257745.png)

通过这个方式，哨兵B和哨兵C也可以建立网络连接，这样一来，哨兵集群就形成了。



> **哨兵集群会对从节点的运行状态进行监控，那么哨兵集群是如何得知从节点的信息**

主节点知道所有从节点的信息，所以哨兵会每10秒一次的频率向主节点发送INFO命令来获取所有从节点的信息。

如下图所示，哨兵B向主节点发送INFO命令，主节点接收到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵A和哨兵C可以通过相同的方法和从节点建立连接。

![img](https://raw.githubusercontent.com/lqyspace/mypic/master/PicBed/202307311823305.png)

正式通过redis的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时哨兵又可以通过INFO命令，在主节点那里获得所有从节点的连接信息，于是就能和从节点建立连接，并进行监控了。



> **总结**

Redis在2.8版本以后提供的哨兵机制（Sentinel），它的作用主要是主从节点故障转移。它会检测主节点是否存活，如果主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵一般是以集群的方式部署的，至少需要三个哨兵，哨兵集群主要负责的三件事情：==监控、选主、通知。==

哨兵节点通过Redis 的发布者/订阅者机制，哨兵之间是可以相互感知的，相互连接的。然后组成哨兵集群，同时哨兵又通过INFO命令，在主节点那里获得所有从节点的链接信息，于是就能和从节点建立连接，并进行监控。

**1、第一轮投票：判断主节点下线**

当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他的哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络连接状况，做出赞成投票和拒绝投票的响应。

当这个哨兵的赞成投票达到哨兵配置文件中的quorum配置项设定的值后，这是主节点就会被该哨兵标记为 “客观下线”。

**2、第二轮投票：选出哨兵leader**

某个哨兵节点判定主节点为客观下线后，该哨兵就会发起投票，告诉其他的哨兵，它想成为leader。想成为leader的哨兵，要满足下面2个条件：

- 第一、那半数以上的赞成票
- 第二、拿到的票数同时还需要大于等于哨兵配置文件中的quorum值

**3、由哨兵leader进行故障转移**

选举出哨兵leader后就可以进行故障转移的过程了，该操作包括以下四个步骤：

- 第一步：在已下线的主节点（旧主节点）属下的所有从节点里面，挑选出一个从节点，并将其转换为主节点，选择的机制：
  - 过滤掉已经离线的从节点
  - 过滤掉历史网络连接状况不好的从节点
  - 将剩下的从节点，进行三轮考察：优先级、复制进度、ID号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。
- 第二步：让已下线主节点属下的所有从节点修改复制目标，修改为复制新主节点
- 第三步：将新主节点的IP地址和信息，通过发布者/订阅者机制通知给客户端
- 第四步：继续监视旧主节点，当这个旧主节点重新上线后，将它设置为新主节点的从节点；



## 为什么要有集群？

Redis哨兵模式，主要是解决高可用问题，在master主节点宕机时，slave从节点自动切换为master主节点。

**1、并发量**

通常来说，单台Redis能够执行10万/秒的命令，这个并发基本上能够满足我们所有的需求，但有时候，比如做离线计算，为了更快的得出结果，有时候我们希望超过这个并发量，这个时候单机就不能满足我们的需求了。

**2、数据量**

通常来说，单台服务器的内存大概在16-256G之间，前面我们说redis数据量都是存储在内存中的，那如果实际业务要保存在Redis的数据超过了单台机器的内存，这个时候最简单的办法就是增加服务器内存，但是单台服务器的内存不可能无限制的增加，纵向扩展不了，那么就横向扩展。这个时候哦我们就会想将这些业务数据分散存储在多台redis服务器中，但是要保证多台Redis服务器能够无阻碍的进行内存数据沟通，这也就是Redis集群的作用。

























